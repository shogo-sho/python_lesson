# -*- coding: utf-8 -*-
# Streamlit app: ãƒã‚±ãƒ¢ãƒ³ç¨®æ—å€¤ï¼‹ç‰¹æ€§æ¤œç´¢ï¼ˆå›ºå®šCSVãƒ»ãƒœã‚¿ãƒ³ãªã—ãƒ»ã‚¿ãƒ–è¡¨ç¤ºï¼‰
# èµ·å‹•ã—ãŸã„æ™‚ã¯ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«ã€€streamlit run pokemon_stat_viewer_streamlit.py

import re
import unicodedata
import pandas as pd
import streamlit as st

# ------------------------------
# è¨­å®š
# ------------------------------
CSV_PATH = "/Users/shogo/Documents/csv/ãƒã‚±ãƒ¢ãƒ³å…¨å›½å›³é‘‘ä¸€è¦§.csv"  # ã“ã® .py ã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ç½®ã

st.set_page_config(page_title="ãƒã‚±ãƒ¢ãƒ³ ç¨®æ—å€¤ãƒ»ç‰¹æ€§ æ¤œç´¢", page_icon="ğŸ”", layout="centered")

# ------------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ------------------------------
def normalize_text(s: str) -> str:
    if not isinstance(s, str):
        return ""
    s = unicodedata.normalize("NFKC", s)
    s = s.lower().strip()
    s = re.sub(r"[ãƒ»ï½¥\u3000\s]+", "", s)
    return s

def collect_ability_columns(cols):
    candidates = ["ç‰¹æ€§", "ç‰¹æ€§1", "ç‰¹æ€§2", "å¤¢ç‰¹æ€§", "éš ã‚Œç‰¹æ€§", "ability", "ability1", "ability2", "hidden"]
    found = []
    for c in cols:
        nc = normalize_text(c)
        for cand in candidates:
            if normalize_text(cand) in nc:
                found.append(c)
                break
    # é‡è¤‡é™¤å»ï¼ˆé †åºç¶­æŒï¼‰
    return list(dict.fromkeys(found))

def extract_abilities(row, ability_cols):
    vals = []
    for c in ability_cols:
        v = row.get(c, "")
        if pd.isna(v) or v is None:
            continue
        s = str(v)
        parts = re.split(r"[\/ï¼,ã€ãƒ»ã€€\|\s]+", s)
        for p in parts:
            p = p.strip()
            if p and p != "-":
                vals.append(p)
    # é‡è¤‡é™¤å»ï¼ˆé †åºç¶­æŒï¼‰
    out, seen = [], set()
    for v in vals:
        if v not in seen:
            out.append(v); seen.add(v)
    return out

def show_one_pokemon(row, ability_cols, name_col, stat_cols):
    # è¡¨ç¤ºç”¨ãƒ†ãƒ¼ãƒ–ãƒ«
    rows = []
    labels = [("HP","hp"), ("æ”»æ’ƒ","atk"), ("é˜²å¾¡","def"), ("ç‰¹æ”»","spa"), ("ç‰¹é˜²","spd"), ("ç´ æ—©ã•","spe"), ("åˆè¨ˆ","bst")]
    for (label, key) in labels:
        colname = stat_cols.get(key)
        if colname and colname in row.index:
            rows.append({"é …ç›®": label, "å€¤": row.get(colname, "")})
    st.subheader(f"ğŸ“˜ {row[name_col]}")
    if rows:
        st.table(pd.DataFrame(rows))
    abilities = extract_abilities(row, ability_cols)
    st.subheader("âœ¨ ç‰¹æ€§")
    if abilities:
        for ab in abilities:
            st.write(f"- {ab}")
    else:
        st.write("ï¼ˆç‰¹æ€§æƒ…å ±ãªã—ï¼‰")

# ------------------------------
# CSVèª­ã¿è¾¼ã¿
# ------------------------------
try:
    df = pd.read_csv(CSV_PATH)
except Exception:
    df = pd.read_csv(CSV_PATH, encoding="cp932")

st.success(f"CSVèª­è¾¼ OKï¼ˆ{len(df)} è¡Œ, {len(df.columns)} åˆ—ï¼‰")

# åˆ—åæ¨å®šï¼ˆæœ€ä½é™ã®å‰æï¼šåå‰ï¼‹ä¸»è¦ã‚¹ãƒ†ï¼‰
cols = list(df.columns)
name_col = "åå‰" if "åå‰" in cols else cols[0]

def pick(cols, candidates):
    nmap = {c: normalize_text(c) for c in cols}
    for cand in candidates:
        nc = normalize_text(cand)
        for col, ncol in nmap.items():
            if nc == ncol:
                return col
    for cand in candidates:
        nc = normalize_text(cand)
        for col, ncol in nmap.items():
            if (nc in ncol) or (ncol in nc):
                return col
    return None

stat_cols = {
    "hp":  pick(cols, ["hp","ï¼¨ï¼°","HP"]),
    "atk": pick(cols, ["æ”»æ’ƒ","ã“ã†ã’ã","atk"]),
    "def": pick(cols, ["é˜²å¾¡","ã¼ã†ãã‚‡","def"]),
    "spa": pick(cols, ["ç‰¹æ”»","ã¨ãã“ã†","spa"]),
    "spd": pick(cols, ["ç‰¹é˜²","ã¨ãã¼ã†","spd"]),
    "spe": pick(cols, ["ç´ æ—©ã•","ã™ã°ã‚„ã•","spe"]),
    "bst": pick(cols, ["åˆè¨ˆ","åˆè¨ˆå€¤","åˆè¨ˆç¨®æ—å€¤","total","bst"]),
}

ability_cols = collect_ability_columns(cols)

# ------------------------------
# æ¤œç´¢UIï¼ˆãƒœã‚¿ãƒ³ãªã—ï¼‰
# ------------------------------
st.title("ğŸ” ãƒã‚±ãƒ¢ãƒ³ ç¨®æ—å€¤ãƒ»ç‰¹æ€§ æ¤œç´¢ï¼ˆå›ºå®šCSVç‰ˆï¼‰")

q = st.text_input("ãƒã‚±ãƒ¢ãƒ³åã‚’å…¥åŠ›ï¼ˆéƒ¨åˆ†ä¸€è‡´OKãƒ»ãƒœã‚¿ãƒ³ä¸è¦ï¼‰", value="", key="query")

if q.strip():
    nq = normalize_text(q)
    names = df[name_col].fillna("").astype(str)
    mask = names.apply(lambda s: nq in normalize_text(s))
    cand = df[mask]

    count = len(cand)
    if count == 0:
        st.warning("ãƒ’ãƒƒãƒˆã—ã¾ã›ã‚“ã§ã—ãŸã€‚è¡¨è¨˜ã‚’å¤‰ãˆã¦å†æ¤œç´¢ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
    elif count == 1:
        show_one_pokemon(cand.iloc[0], ability_cols, name_col, stat_cols)
    else:
        st.info(f"{count}ä»¶ãƒ’ãƒƒãƒˆã€‚10ä»¶ã¾ã§ã¯ã‚¿ãƒ–ã§åˆ‡æ›¿ãˆã‚‰ã‚Œã¾ã™ã€‚11ä»¶ä»¥ä¸Šã¯ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ã§é¸æŠã—ã¦è¡¨ç¤ºã—ã¾ã™ã€‚")

        if count <= 10:
            labels = [str(v) for v in cand[name_col].astype(str).tolist()]
            tabs = st.tabs(labels)
            for tab, (_, row) in zip(tabs, cand.iterrows()):
                with tab:
                    show_one_pokemon(row, ability_cols, name_col, stat_cols)
        else:
            options = list(cand[name_col].astype(str))
            choice = st.selectbox("å€™è£œã‹ã‚‰é¸æŠ", options=options, key="choice")
            picked = cand[cand[name_col].astype(str) == choice].iloc[0]
            show_one_pokemon(picked, ability_cols, name_col, stat_cols)
else:
    st.info("æ¤œç´¢æ¬„ã«åå‰ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€å€™è£œã¨è©³ç´°ãŒã™ãã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")